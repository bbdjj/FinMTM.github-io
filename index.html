<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="FinMTM: A Multi-Turn Multimodal Benchmark for \\ Financial Reasoning and Agent Evaluation">
    <meta name="keywords" content="text-to-image generation, Large Language Models, scene synthesis">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>FinMTM</title> 

    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
S
        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">
    <link rel="icon" href="./static/images/logo.png">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <link rel="stylesheet" href="./static/css/index-gradio.css">
    <link rel="stylesheet" href="./static/css/live_theme.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <!-- <script src="./static/js/index.js"></script> -->
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title"
                        style="display: flex;flex-direction: row;align-items: center;justify-content: center;margin-bottom: 5px;"><img
                            src="./static/images/logo.png" width="60" height="60" style="margin-right: 10px;">FinMTM:</h1>
                    <h1 class="title is-2 publication-title">A Multi-Turn Multimodal Benchmark for Financial Reasoning and Agent Evaluation</h1>
                    <div class="is-size-5 publication-authors">
            <span class="author-block">
              Chenxi Zhang<sup>1,2</sup> </a>,</span>
                        <span class="author-block">
              Ziliang Gan<sup>1</sup></a>, Liyun Zhu<sup>1</sup>, Youwei Pang<sup>3</sup>,  Qing Zhang<sup>4</sup>, Rongjunchen Zhang<sup>1</sup> 
             </a>
            </span>
            <br>
            <!-- <span class="author-block">
                Chaoyou Fu<sup>4</sup>, Zenglin Xu<sup>5</sup>, Rongjunchen Zhang<sup>1</sup>, Yong Dai<sup>1</sup>
            </span> -->
                    </div>
                    <div class="is-size-5 publication-authors" style="margin-top: 10px;">
                        <span class="author-block">
                            <sup>1</sup>Hithink Research, <sup>2</sup>Wuhan University, <sup>3</sup>Nanyang Technological University, <sup>4</sup>Shanghai Institute of Technology ,
                        </span>

                    </div>

    </div>
</section>

<div class="column has-text-centered">
    <div class="publication-links">
      <!-- PDF Link. -->
      <span class="link-block"> <a href=""
           class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="ai ai-arxiv"></i> </span> <span>arXiv</span> </a> </span>
      <!-- Code Link. -->
      <span class="link-block"> <a href="https://github.com/HiThink-Research/FinMTM"
           class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="fab fa-github"></i> </span> <span>Code</span> </a> </span>
      <!-- HuggingFace Link. -->
      <span class="link-block"> <a href="https://huggingface.co/datasets/hithink-ai/FinMTM"
           class="external-link button is-normal is-rounded is-dark"><span class="icon">ðŸ¤—</span><span>Space</span> </a></span>
  
    </div>

      <figure class="image is-inline-block" style="max-width: 1620px; margin-top: 14px; padding-left: 300px;">
        <img src="./static/images/Columnar.png"
             alt="Teaser"
             loading="lazy"
             decoding="async"
             style="width: 80%; height: auto; display: block;">
      </figure>
      </div>

    


<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-2">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        The financial domain poses substantial challenges for vision-language models (VLMs) due to specialized chart formats and knowledge-intensive reasoning requirements. 
However, existing financial benchmarks are largely single-turn and rely on a narrow set of question formats, limiting comprehensive evaluation in realistic application scenarios.
To address this gap, we propose FinMTM, a multi-turn multimodal benchmark that expands diversity along both data and task dimensions. 
On the data side, we curate and annotate 11{,}133 bilingual (Chinese and English) financial QA pairs grounded in financial visuals, including candlestick charts, statistical plots, and report figures.
On the task side, FinMTM covers single- and multiple-choice questions, multi-turn open-ended dialogues, and agent-based tasks.
We further design task-specific evaluation protocols, including a set-overlap scoring rule for multiple-choice questions, a weighted combination of turn-level and session-level scores for multi-turn dialogues, and a composite metric that integrates planning quality with final outcomes for agent tasks.
Extensive experimental evaluation of 22 VLMs reveal their limitations in fine-grained visual perception, long-context reasoning, and complex agent workflows.</p>
                </div>
            </div>
        </div>
        <!--/ Abstract. -->
    </div>
</section>


<section class="section">
    
    <div class="container is-max-desktop">
        
        <div class="columns is-centered has-text-centered">
            <h2 class="title is-2">Overview</h2>
            <br>
        </div>

        <!-- Architecture -->
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h4 class="title is-3">â€¢Data Collection </h4>
                <div class="content has-text-justified">
                    <p>
                        FinMTM is a robust multimodal benchmark curated from real-world financial workflows, integrating diverse data from U.S. and Chinese corporate disclosures, research reports, and financial media. The dataset is structured around three core components: expert-validated objective questions utilizing a "negative selection" paradigm to enhance evaluative rigor; multi-turn open-ended dialogues categorized into a four-level cognitive hierarchy (L<sub>1</sub>â€“L<sub>4</sub>) that blend automated generation with manual refinement for realistic interaction; and a sophisticated financial agentic pipeline that synthesizes verifiable tool-calling trajectories through knowledge-base integration and entity-obfuscation strategies. By combining professional fidelity with high-difficulty task design, FinMTM provides a comprehensive framework for benchmarking the long-context reasoning, retrieval, and decision-making capabilities of models in authentic financial scenarios.
                      </p>
                    <img class="columns is-centered has-text-centered" src="./static/images/main2.png" alt="Teaser" width="95%"
                         style="margin:0 auto">
                    <br>
                    <figcaption>
                        <p style="text-align: center; color: #1d3f9c;">
                        </p>
                    </figcaption>
                </div>
                <h4 class="title is-3">â€¢Financial Agent Question Generation</h4>
                <p>
                    To construct high-quality benchmarks for financial intelligence, FinMTM employs a two-stage synthesis pipeline designed to generate verifiable agentic trajectories and tool-calling sequences. The process begins with the establishment of two specialized knowledge basesâ€”a general factual repository (K<sub>1</sub>) and a document-centric base (K<sub>2</sub>)â€”which serve as the ground-truth anchors for financial facts and tool parameters. Building upon these, the framework generates initial Q&A pairs that simulate real-world analyst workflows. To ensure the rigor of the evaluation, a specialized "fuzz" strategy is then applied to systematically obfuscate entity priors within the questions and mask sensitive visual regions (such as company names). This approach prevents models from relying on pre-trained memory, forcing the agents to demonstrate authentic retrieval-augmented reasoning and precise tool-use capabilities in complex financial scenarios.
                  </p>
                    <div class="content has-text-justified">
                        <br>
                        <br>
                    <img class="columns is-centered has-text-centered" src="./static/images/12d206da-5383-4200-9290-d43333931b24.png" alt="Teaser" width="95%"
                        style="margin:0 auto">
                    <br>
                    <figcaption>
                        <p style="text-align: center; color: #061E61;">
                        </p>
                    </figcaption>
                    </div>
                <h4 class="title is-3">â€¢Evaluation Method </h4>
                    <div class="content has-text-justified">
                        <p>
                            FinMTM employs a rigorous evaluation framework tailored to specific task types. For objective questions, it utilizes a deterministic protocol with a strict overselection rule where any incorrect selection results in a zero score while partial credit is assigned proportionally for correct answers. Open-ended multi-turn dialogues are assessed using a dual-rule strategy that evaluates turn-level capabilities across five dimensions including visual precision, financial logic, data accuracy, cross-modal verification, and temporal awareness combined with session-level checklist verification. Financial agent tasks are measured through a two-stage trajectory-based framework consisting of a planning stage that quantifies tool usage quality via an F<sub>&beta;</sub> score based on functional alignment and a summarization stage evaluating reasoning quality (Q<sup>r</sup>) and answer correctness (Q<sup>a</sup>). To ensure high reliability and industry authority, the benchmark implements a multi-model cross-evaluation protocol using LLM judges like GPT-5 and Gemini-3 Pro which is further validated by hierarchical audits from a team of fifteen senior financial experts.
                          </p>
                    <img class="columns is-centered has-text-centered" src="./static/images/eval.png" alt="Teaser" width="95%"
                        style="margin:0 auto">
                    <br>
                    <figcaption>
                        <p style="text-align: center; color: #061E61;">
                        </p>
                    </figcaption>
                    </div>
                <h4 class="title is-3">â€¢Statistics </h4>
                    <div class="content has-text-justified">
                        <p>
                            Our benchmark consists of three main tasks with 11,133 questions with 3600 images and 400 PDFs. It covers stocks from both the U.S. and Chinese A-share markets, spanning multiple industries, and reflects diverse real-world financial settings.
The objective questions include 1,982 single-choice and 1,982 multiple-choice questions, assessing a modelâ€™s basic understanding of financial multimodal information under clearly defined constraints. Open-ended questions contain 6,169 samples, with an average of 4.25 interaction rounds per sample and 4,963 average input tokens.
Finally, the financial agent task includes 1,000 samples, all requiring external financial tools. About 73\% of the tasks can be completed using a single tool across multiple calls, while the remaining 27\% require multiple tools. This setting reflects realistic financial analysis and decision-making workflows.
                        </p>
                   
                          <img class="columns is-centered has-text-centered" src="./static/images/static.png" alt="Teaser" width="95%"
                          style="margin:0 auto">
                    <br>
                    <figcaption>
                        <p style="text-align: center; color: #061E61;">
                        </p>
                    </figcaption>
                    </div>
            </div>
        </div>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <h2 class="title is-2">Results on FinMTM</h2>
            <br>
        </div>
        <div class="columns is-centered">
            <div class="column is-full-width"> 
                <div class="content has-text-justified">
                    <p>
                        Proprietary models lead across most evaluation dimensions where Gemini 3 Pro excels in open-ended tasks including comprehension and memory while GPT-5 achieves peak performance in multiple-choice questions. Gemini 3 Flash demonstrates the strongest agentic capability for autonomous decision making in both fuzzed and non-fuzzed financial agent scenarios. Although open-source models like the Qwen and InternVL series are competitive in objective single-turn tasks, they exhibit sharp performance degradation in self-correction and long-horizon memory scenarios. This gap underscores the limitations of current open-source models in managing complex multi-step reasoning and tool-based financial workflows.
                      </p>
                    <img class="columns is-centered has-text-centered" src="./static/images/17e9fc9a-a2b2-48f5-a450-a10fd1881d9a.png" alt="Teaser" width="85%"
                         style="margin:0 auto">
                    <br>



<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <h2 class="title is-2">Demonstrations</h2>
            <br>
        </div>
        <div class="columns is-centered">
            <div class="column is-full-width"> 
                <h3 class="title is-4">â€¢ Muti-turn Open-ended Questions</h3>
                    <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="./static/images/sample1.png" alt="Teaser" width="95%"
                         style="margin:0 auto">
                    <br>
                    </div>
                <h3 class="title is-4">â€¢ Financial Agentic Questions</h3>
                    <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="./static/images/sample2.png" alt="Teaser" width="95%"
                         style="margin:0 auto">
                    <br>
                <h3 class="title is-4">â€¢ Objective Questions</h3>
                    <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="./static/images/sample3.png" alt="Teaser" width="95%"
                         style="margin:0 auto">
                    <br>
                    </div>
                    </div>